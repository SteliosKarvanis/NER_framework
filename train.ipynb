{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import datetime\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, TrainingArguments, Trainer, AutoModelForTokenClassification, pipeline, EarlyStoppingCallback\n",
    "\n",
    "from labels import LABELS\n",
    "from utils import load_data, create_dataset_dict, generate_tokenized_datasets, compute_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file must be in format of the output of the labelling tool\n",
    "a txt file with a list of json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(\"data_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Kit Shampoo Revitay Óleo de Coco Novex 300ml e Condicionador Revitay Óleo de Coco Novex 300ml',\n",
       " 'tags': [['O', 0, 3],\n",
       "  ['B-PRO', 4, 11],\n",
       "  ['B-ESP', 12, 19],\n",
       "  ['B-ESP', 20, 24],\n",
       "  ['I-ESP', 25, 27],\n",
       "  ['I-ESP', 28, 32],\n",
       "  ['B-MAR', 33, 38],\n",
       "  ['B-TAM', 39, 44],\n",
       "  ['O', 45, 46],\n",
       "  ['B-PRO', 47, 60],\n",
       "  ['B-ESP', 61, 68],\n",
       "  ['B-ESP', 69, 73],\n",
       "  ['I-ESP', 74, 76],\n",
       "  ['I-ESP', 77, 81],\n",
       "  ['B-MAR', 82, 87],\n",
       "  ['B-TAM', 88, 93]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens'],\n",
       "        num_rows: 403\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'ner_tags', 'tokens'],\n",
       "        num_rows: 101\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = create_dataset_dict(data, test_size=0.2)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {i: label for i, label in enumerate(LABELS)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME, max_length=512, truncation=True)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a3e83760b3495cbc4d2d7f14333d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/403 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab0600f952641219e0e5f2e826ec524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/101 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = generate_tokenized_datasets(tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_dir = f\"bert_finetuned_ner_{int(datetime.datetime.now().timestamp())}\"\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"precision\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff358eec3b34663a4a1540480c1a81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/510 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425cb3b8bb46494f9e4735546ff2f337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stelios/.virtualenvs/ita/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6473009586334229, 'eval_precision': 0.6486042692939245, 'eval_recall': 0.7655038759689923, 'eval_f1': 0.7022222222222222, 'eval_accuracy': 0.80548128342246, 'eval_runtime': 2.6106, 'eval_samples_per_second': 38.689, 'eval_steps_per_second': 4.98, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc328a7b2e044af8ef6ed3a44d6d132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4726336598396301, 'eval_precision': 0.7368421052631579, 'eval_recall': 0.813953488372093, 'eval_f1': 0.7734806629834253, 'eval_accuracy': 0.8449197860962567, 'eval_runtime': 1.5393, 'eval_samples_per_second': 65.613, 'eval_steps_per_second': 8.445, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138fbfe655ac42c0bb6c77fec1e2df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4285411536693573, 'eval_precision': 0.8025594149908593, 'eval_recall': 0.8507751937984496, 'eval_f1': 0.8259642521166509, 'eval_accuracy': 0.8683155080213903, 'eval_runtime': 1.4218, 'eval_samples_per_second': 71.037, 'eval_steps_per_second': 9.143, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c45c8d85ec4e5b942c33484e7b2a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42887091636657715, 'eval_precision': 0.8144712430426716, 'eval_recall': 0.8507751937984496, 'eval_f1': 0.8322274881516587, 'eval_accuracy': 0.8716577540106952, 'eval_runtime': 1.3688, 'eval_samples_per_second': 73.785, 'eval_steps_per_second': 9.497, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab3979b2d424f0c9a4802ce9fa3d0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4599468410015106, 'eval_precision': 0.8161764705882353, 'eval_recall': 0.8604651162790697, 'eval_f1': 0.8377358490566038, 'eval_accuracy': 0.8656417112299465, 'eval_runtime': 1.3574, 'eval_samples_per_second': 74.406, 'eval_steps_per_second': 9.577, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5537aece52c43c0b5bebc947ba33f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.465029776096344, 'eval_precision': 0.8296296296296296, 'eval_recall': 0.8682170542635659, 'eval_f1': 0.8484848484848484, 'eval_accuracy': 0.8770053475935828, 'eval_runtime': 1.3981, 'eval_samples_per_second': 72.241, 'eval_steps_per_second': 9.298, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900ee487a5fa4f59892ff11a0f522f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.48287132382392883, 'eval_precision': 0.8107606679035251, 'eval_recall': 0.8468992248062015, 'eval_f1': 0.828436018957346, 'eval_accuracy': 0.8703208556149733, 'eval_runtime': 1.2633, 'eval_samples_per_second': 79.947, 'eval_steps_per_second': 10.29, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286ea77da2ca471c864f6e43cf6e2951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49582597613334656, 'eval_precision': 0.813780260707635, 'eval_recall': 0.8468992248062015, 'eval_f1': 0.8300094966761633, 'eval_accuracy': 0.8709893048128342, 'eval_runtime': 1.482, 'eval_samples_per_second': 68.151, 'eval_steps_per_second': 8.772, 'epoch': 8.0}\n",
      "{'train_runtime': 59.0895, 'train_samples_per_second': 68.202, 'train_steps_per_second': 8.631, 'train_loss': 0.4547533147475299, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=408, training_loss=0.4547533147475299, metrics={'train_runtime': 59.0895, 'train_samples_per_second': 68.202, 'train_steps_per_second': 8.631, 'train_loss': 0.4547533147475299, 'epoch': 8.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e7294b4b854753968e89d0f203e754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.465029776096344,\n",
       " 'eval_precision': 0.8296296296296296,\n",
       " 'eval_recall': 0.8682170542635659,\n",
       " 'eval_f1': 0.8484848484848484,\n",
       " 'eval_accuracy': 0.8770053475935828,\n",
       " 'eval_runtime': 2.4617,\n",
       " 'eval_samples_per_second': 41.028,\n",
       " 'eval_steps_per_second': 5.281,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tunned_model_path = \"best_bert_finetuned_ner\"\n",
    "trainer.save_model(fine_tunned_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=fine_tunned_model_path, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predict(text):\n",
    "    tokens = token_classifier(text)\n",
    "    print(text)\n",
    "    for token in tokens:\n",
    "        if token:\n",
    "            print(f\"{token['word']} : {token['entity_group']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coca Cola 1L\n",
      "Coca Cola : PRO\n",
      "1L : TAM\n"
     ]
    }
   ],
   "source": [
    "show_predict(\"Coca Cola 1L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
